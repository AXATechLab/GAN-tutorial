{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!(nvidia-smi | grep -q \"has failed\") && echo \"No GPU found!\" || nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/MNIST_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the input data. Notice that the `x_train` data is for visualization, we define training data in network later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = mnist.train.images[:55000,:]\n",
    "x_train.shape\n",
    "\n",
    "randomNum = random.randint(0,55000)\n",
    "image = x_train[randomNum].reshape([28,28])\n",
    "plt.imshow(image,cmap=plt.get_cmap('gray_r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(input=x,filter=W,strides=[1,1,1,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_withwb(x, k_w=3, k_h=3, input_channel=1, output_channel=8, stride=1, name='conv2d', reuse=False):\n",
    "    \"\"\"\n",
    "    k_w: kernel width\n",
    "    k_h: kernel height\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        w = tf.get_variable('w', [k_w, k_h, input_channel, output_channel],\n",
    "                            initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b = tf.get_variable('b', [output_channel], initializer=tf.constant_initializer(0))\n",
    "\n",
    "    return tf.nn.conv2d(x, w, strides=[1,stride,stride,1], padding='SAME') + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_pool_2x2(x,stride=2):\n",
    "    return tf.nn.avg_pool(x, ksize=[1,2,2,1], strides=[1,stride,stride,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv2d(x, k_w=3, k_h=3, output_shape=[1,1,1,1], stride=2, padding='SAME', name='deconv', reuse=False):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        w = tf.get_variable('w', [k_w, k_h, output_shape[-1], int(x.get_shape()[-1])], \n",
    "                            initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b = tf.get_variable('b', [output_shape[-1]], initializer=tf.constant_initializer(0.1))\n",
    "    \n",
    "    return b + tf.nn.conv2d_transpose(x, w, output_shape=output_shape, strides=[1,stride,stride,1], padding=padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO TASK: \n",
    "\n",
    "Build discriminator network\n",
    "\n",
    "Input: One batch of images with each image having scale `[28,28]` So input size is `[batch_size,28,28]`\n",
    "\n",
    "Output: A vector with dimension `[batch_size,1]`. (Discriminator outputs a scalar for each sample, so for one batch it outpus `[batch_size,1]`)\n",
    "\n",
    "**Task 1.1**: \n",
    "\n",
    "Build network architecture use convolutional layer with `stride=1`, add `tf.nn.relu` as activation function. Use max pool to downsample.\n",
    "\n",
    "---\n",
    "\n",
    "**Task 2.1**: \n",
    "\n",
    "(Yes, this is **first** part of **task 2**. You will come back to this part after finishing **task 1**)\n",
    "\n",
    "Build network architecture use convolutional layer with `stride=2`, add `tf.nn.relu` as activation function. **No** max pool.\n",
    "\n",
    "---\n",
    "\n",
    "**Task 3.1**:\n",
    "\n",
    "(As above, this is, again, **first** part of **task 3**. Come back to it after finishing **task 2**)\n",
    "\n",
    "Build network ONLY with 2 or 3 fully connect layer  (`tf.layers.dense`). Suggested number of hidden unit: 256.\n",
    "\n",
    "---\n",
    "\n",
    "Compare the results from the different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x,reuse=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):            \n",
    "        # First conv and pool layer\n",
    "        h_conv1 = conv2d_withwb(x,3,3,1,8,s=2,name='d_conv1')\n",
    "        h_conv1 = tf.nn.leaky_relu(h_conv1)\n",
    "        \n",
    "        # TO Do: complete the rest layers:\n",
    "\n",
    "        \n",
    "    return y_conv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_task2(x,reuse=False):\n",
    "    with tf.variable_scope('discriminator_task2', reuse=reuse):            \n",
    "        # First conv and pool layer\n",
    "        h_conv1 = conv2d_withwb(x, 3, 3, 1, 8, stride=2, name='d_conv1')\n",
    "        \n",
    "        # TO Do: complete the rest layers:\n",
    "        \n",
    "    return tf.nn.sigmoid(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_fc(x,batch_size,reuse=False):\n",
    "    with tf.variable_scope('discriminator_simple', reuse=reuse):\n",
    "        x = tf.reshape(x, [batch_size, -1])\n",
    "        \n",
    "        # TO Do: complete the rest layers:\n",
    "\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO TASK: \n",
    "\n",
    "Build Generator network\n",
    "\n",
    "Input: noise vector z \n",
    "\n",
    "Output: sample image with dimension `28*28`\n",
    "\n",
    "**Task 1.2**\n",
    "Architecture: use `tf.nn.conv2d_transpose` to build 3 or 4 deconvolutional layer. Add `tf.nn.relu` after deconvolutional layer. Use `tf.nn.tahn` as activation function for the last layer.\n",
    "\n",
    "**Task 2.2**\n",
    "Add batch normalization after each deconvolutional layer using function `tf.contrib.layers.batch_norm`. And add `tf.nn.relu` after batch normalizatoin.  \n",
    "\n",
    "**Task 3.2**\n",
    "Build network with ONLY 2 or 3 fully connected layer (`tf.layers.dense`). Reshape the output of last layer to `[batch_size,28,28,1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, batch_size, z_dim, reuse=False):\n",
    "    with tf.variable_scope('generator_new', reuse=reuse):\n",
    "        g_dim = 64 # numbers of filters of first layer of generator\n",
    "        c_dim = 1 # color dimension of output (MNIST is grayscale, so c_dim = 1 for us)\n",
    "        s = 28 # output size of the image\n",
    "        \n",
    "        h0 = tf.reshape(z, [batch_size, 2, 2, 25]) \n",
    "        h0 = tf.nn.relu(h0)\n",
    "        \n",
    "        # example for first layer\n",
    "        output_shape = [batch_size,4,4,g_dim*8]\n",
    "        h_deconv1 = deconv2d(h0,output_shape=output_shape,name='g_deconv1')\n",
    "        h_deconv1 = tf.nn.relu(h_deconv1)\n",
    "        # Dimensions of H_conv1 = batch_size x 3 x 3 x 256\n",
    "        \n",
    "        # TO DO: complete the rest layers here:\n",
    "        \n",
    "    return H_conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_task2(z, batch_size, z_dim,reuse=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):        \n",
    "        g_dim = 64 # numbers of filters of first layer of generator\n",
    "        c_dim = 1 # color dimension of output (MNIST is grayscale, so c_dim = 1 for us)\n",
    "        s = 28 # output size of the image\n",
    "        \n",
    "        # TO DO: complete the rest layers here:\n",
    "\n",
    "    return H_conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_fc(x,batch_size, z_dim,reuse=False):\n",
    "    with tf.variable_scope('generator_simple',reuse=reuse):\n",
    "        # TO DO: complete the rest layers here:\n",
    "\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "tf.reset_default_graph() # Since we changed our batch size (from 1 to 16), we need to reset our Tensorflow graph\n",
    "z_dimensions = 100\n",
    "\n",
    "x_placeholder = tf.placeholder(\"float\", shape = [batch_size,28,28,1]) # Placeholder for input images to the discriminator\n",
    "z_placeholder = tf.placeholder(tf.float32, [batch_size, z_dimensions]) # Placeholder for input noise vectors to the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call generator to get sample data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dx = discriminator_fc(x_placeholder,batch_size,reuse=False) # Dx will hold discriminator prediction probabilities for the real MNIST images\n",
    "Gz = generator_fc(z_placeholder, batch_size, z_dimensions) # Gz holds the generated images\n",
    "Dg = discriminator_fc(Gz,batch_size, reuse=True) # Dg will hold discriminator prediction probabilities for generated images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO TASK: complete the generator loss and discriminator loss according to the objective function.\n",
    "\n",
    "Generator loss: ![generator loss](../images/generator_loss.png)\n",
    "\n",
    "Discriminator loss: ![discriminator loss](../images/discriminator_loss.png)\n",
    "\n",
    "Note that: when discriminator is updated, the generator is fixed; And when generator is updated, the discriminator is fixed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss = # TODO\n",
    "\n",
    "d_loss_real = # TODO\n",
    "d_loss_fake = # TODO\n",
    "d_loss = d_loss_real + d_loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "d_vars = [var for var in tvars if 'discriminator' in var.name]\n",
    "g_vars = [var for var in tvars if 'generator' in var.name]\n",
    "print(d_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.train.AdamOptimizer()\n",
    "trainerD = tf.train.AdamOptimizer(learning_rate=0.0002).minimize(d_loss, var_list=d_vars)\n",
    "trainerG =  tf.train.AdamOptimizer(learning_rate=0.0002).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 50000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        z_batch = np.random.uniform(-1, 1, size=[batch_size, z_dimensions])\n",
    "        real_image_batch = mnist.train.next_batch(batch_size)\n",
    "        real_image_batch = np.reshape(real_image_batch[0], [batch_size,28,28,1])\n",
    "        _,d_loss_value = sess.run([trainerD, d_loss], # Update the discriminator\n",
    "                           feed_dict={z_placeholder: z_batch,\n",
    "                                      x_placeholder: real_image_batch}) \n",
    "        _,g_loss_value, g = sess.run([trainerG, g_loss, Gz],  # Update the generator\n",
    "                             feed_dict={z_placeholder:z_batch})\n",
    "\n",
    "        if i%2000==1:\n",
    "            print('g_loss: ',g_loss_value, 'd_loss: ',d_loss_value)\n",
    "            n = int(np.sqrt(batch_size))\n",
    "            canvas_orig = np.empty((28 * n, 28 * n))\n",
    "            canvas_recon = np.empty((28 * n, 28 * n))\n",
    "            for i in range(n):\n",
    "                # Display original images\n",
    "                for j in range(n):\n",
    "                    # Draw the original digits\n",
    "                    canvas_orig[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = \\\n",
    "                        real_image_batch[n*i+j].reshape([28, 28])\n",
    "                # Display reconstructed images\n",
    "                for j in range(n):\n",
    "                    # Draw the reconstructed digits\n",
    "                    canvas_recon[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = \\\n",
    "                        g[n*i+j].reshape([28, 28])\n",
    "\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(2*n,n), frameon=False)\n",
    "            axes[0].imshow(canvas_orig, origin=\"upper\", cmap=\"gray\")\n",
    "            axes[0].set_title(\"Original Images\")\n",
    "\n",
    "            axes[1].imshow(canvas_recon, origin=\"upper\", cmap=\"gray\")\n",
    "            axes[1].set_title(\"Reconstructed Images\")\n",
    "\n",
    "            axes[0].set_axis_off(); axes[1].set_axis_off()\n",
    "            plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
