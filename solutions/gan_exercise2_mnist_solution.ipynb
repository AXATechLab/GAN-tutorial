{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!(nvidia-smi | grep -q \"has failed\") && echo \"No GPU found!\" || nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/MNIST_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the input data. Notice that the `x_train` data is for visualization, we define training data in network later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = mnist.train.images[:55000,:]\n",
    "x_train.shape\n",
    "\n",
    "randomNum = random.randint(0,55000)\n",
    "image = x_train[randomNum].reshape([28,28])\n",
    "plt.imshow(image,cmap=plt.get_cmap('gray_r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(input=x,filter=W,strides=[1,1,1,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_withwb(x, k_w=3, k_h=3, input_channel=1, output_channel=8, stride=1, name='conv2d', reuse=False):\n",
    "    \"\"\"\n",
    "    k_w: kernel width\n",
    "    k_h: kernel height\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        w = tf.get_variable('w', [k_w, k_h, input_channel, output_channel],\n",
    "                            initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b = tf.get_variable('b', [output_channel], initializer=tf.constant_initializer(0))\n",
    "\n",
    "    return tf.nn.conv2d(x, w, strides=[1,stride,stride,1], padding='SAME') + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_pool_2x2(x,stride=2):\n",
    "    return tf.nn.avg_pool(x, ksize=[1,2,2,1], strides=[1,stride,stride,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv2d(x, k_w=3, k_h=3, output_shape=[1,1,1,1], stride=2, padding='SAME', name='deconv', reuse=False):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        w = tf.get_variable('w', [k_w, k_h, output_shape[-1], int(x.get_shape()[-1])], \n",
    "                            initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b = tf.get_variable('b', [output_shape[-1]], initializer=tf.constant_initializer(0.1))\n",
    "    \n",
    "    return b + tf.nn.conv2d_transpose(x, w, output_shape=output_shape, strides=[1,stride,stride,1], padding=padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO TASK: \n",
    "\n",
    "Build discriminator network\n",
    "\n",
    "Input: One batch of images with each image having scale `[28,28]` So input size is `[batch_size,28,28]`\n",
    "\n",
    "Output: A vector with dimension `[batch_size,1]`. (Discriminator outputs a scalar for each sample, so for one batch it outpus `[batch_size,1]`)\n",
    "\n",
    "**Task 1.1**: \n",
    "\n",
    "Build network architecture use convolutional layer with `stride=1`, add `tf.nn.relu` as activation function. Use max pool to downsample.\n",
    "\n",
    "---\n",
    "\n",
    "**Task 2.1**: \n",
    "\n",
    "(Yes, this is **first** part of **task 2**. You will come back to this part after finishing **task 1**)\n",
    "\n",
    "Build network architecture use convolutional layer with `stride=2`, add `tf.nn.relu` as activation function. **No** max pool.\n",
    "\n",
    "---\n",
    "\n",
    "**Task 3.1**:\n",
    "\n",
    "(As above, this is, again, **first** part of **task 3**. Come back to it after finishing **task 2**)\n",
    "\n",
    "Build network ONLY with 2 or 3 fully connect layer  (`tf.layers.dense`). Suggested number of hidden unit: 256.\n",
    "\n",
    "---\n",
    "\n",
    "Compare the results from the different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x,reuse=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):            \n",
    "        # First conv and pool layer\n",
    "        W_conv1 = tf.get_variable('d_wconv1', [5, 5, 1, 8], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_conv1 = tf.get_variable('d_bconv1', [8],          initializer=tf.constant_initializer(0))\n",
    "        # W.x+b\n",
    "        h_conv1 = tf.nn.leaky_relu(conv2d(x, W_conv1) + b_conv1)\n",
    "        h_pool1 = avg_pool_2x2(h_conv1)\n",
    "\n",
    "        #Second Conv and Pool Layers\n",
    "        W_conv2 = tf.get_variable('d_wconv2', [5, 5, 8, 16], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_conv2 = tf.get_variable('d_bconv2', [16],          initializer=tf.constant_initializer(0))\n",
    "        h_conv2 = tf.nn.leaky_relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "        h_pool2 = avg_pool_2x2(h_conv2)\n",
    "\n",
    "        #First Fully Connected Layer\n",
    "        W_fc1 = tf.get_variable('d_wfc1', [7 * 7 * 16, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_fc1 = tf.get_variable('d_bfc1', [32],             initializer=tf.constant_initializer(0))\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*16])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "        #Second Fully Connected Layer\n",
    "        W_fc2 = tf.get_variable('d_wfc2', [32, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_fc2 = tf.get_variable('d_bfc2', [1],     initializer=tf.constant_initializer(0))\n",
    "\n",
    "        #Final Layer\n",
    "        y_conv=(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "        \n",
    "        y_conv = tf.sigmoid(y_conv)\n",
    "        \n",
    "#         y = tf.layers.dense(h_fc1,units=1)\n",
    "        \n",
    "    return y_conv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_task2(x,reuse=False):\n",
    "    with tf.variable_scope('discriminator_task2', reuse=reuse):            \n",
    "        # First conv and pool layer\n",
    "        h_conv1 = conv2d_withwb(x, 3, 3, 1, 8, stride=2, name='d_conv1')\n",
    "        h_conv1 = tf.contrib.layers.batch_norm(inputs=h_conv1, center=True, scale=True, is_training=True, scope='d_bn1')\n",
    "        h_conv1 = tf.nn.leaky_relu(h_conv1)\n",
    "\n",
    "        h_conv2 = conv2d_withwb(h_conv1, 3, 3, 8, 16, stride=2, name='d_conv2')\n",
    "        h_conv2 = tf.contrib.layers.batch_norm(inputs=h_conv2, center=True, scale=True, is_training=True, scope='d_bn2')\n",
    "        h_conv2 = tf.nn.leaky_relu(h_conv2)\n",
    "\n",
    "        h_conv3 = conv2d_withwb(h_conv2, 3, 3, 16, 32, stride=2, name='d_conv3')\n",
    "        h_conv3 = tf.contrib.layers.batch_norm(inputs=h_conv3, center=True, scale=True, is_training=True, scope='d_bn3')\n",
    "        h_conv3 = tf.nn.leaky_relu(h_conv3)\n",
    "\n",
    "        h_pool3_flat = tf.reshape(h_conv3, [-1, 4*4*32])\n",
    "        h_fc1 = tf.layers.dense(h_pool3_flat, units=32, activation=tf.nn.leaky_relu)\n",
    "\n",
    "        y = tf.layers.dense(h_fc1,units=1)\n",
    "        \n",
    "    return tf.nn.sigmoid(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_fc(x,batch_size,reuse=False):\n",
    "    with tf.variable_scope('discriminator_simple', reuse=reuse):\n",
    "        x = tf.reshape(x, [batch_size, -1])\n",
    "        hidden_layer = tf.layers.dense(x, units=256, activation=tf.nn.leaky_relu)\n",
    "        out_layer = tf.layers.dense(hidden_layer, units=1)\n",
    "        out_layer = tf.nn.sigmoid(out_layer)\n",
    "\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO TASK: \n",
    "\n",
    "Build Generator network\n",
    "\n",
    "Input: noise vector z \n",
    "\n",
    "Output: sample image with dimension `28*28`\n",
    "\n",
    "**Task 1.2**\n",
    "Architecture: use `tf.nn.conv2d_transpose` to build 3 or 4 deconvolutional layer. Add `tf.nn.relu` after deconvolutional layer. Use `tf.nn.tahn` as activation function for the last layer.\n",
    "\n",
    "**Task 2.2**\n",
    "Add batch normalization after each deconvolutional layer using function `tf.contrib.layers.batch_norm`. And add `tf.nn.relu` after batch normalizatoin.  \n",
    "\n",
    "**Task 3.2**\n",
    "Build network with ONLY 2 or 3 fully connected layer (`tf.layers.dense`). Reshape the output of last layer to `[batch_size,28,28,1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_deconv(z, batch_size, z_dim,reuse=False):\n",
    "    with tf.variable_scope('generator_new', reuse=reuse):\n",
    "        g_dim = 64 # numbers of filters of first layer of generator\n",
    "        c_dim = 1 # color dimension of output (MNIST is grayscale, so c_dim = 1 for us)\n",
    "        s = 28 # output size of the image\n",
    "        \n",
    "        h0 = tf.reshape(z, [batch_size, 2, 2, 25]) \n",
    "        h0 = tf.nn.relu(h0)\n",
    "        \n",
    "        output_shape = [batch_size, 4, 4, g_dim*8]\n",
    "        h_deconv1 = deconv2d(h0,output_shape=output_shape,name='g_deconv1')\n",
    "        h_deconv1 = tf.contrib.layers.batch_norm(inputs=h_deconv1, center=True,scale=True,is_training=True,scope='g_bn1')\n",
    "        h_deconv1 = tf.nn.relu(h_deconv1)\n",
    "        \n",
    "        output_shape = [batch_size, 7, 7, g_dim*4]\n",
    "        h_deconv2 = deconv2d(h_deconv1,output_shape=output_shape,name='g_deconv2')\n",
    "        h_deconv2 = tf.contrib.layers.batch_norm(inputs=h_deconv2, center=True, scale=True, is_training=True, scope=\"g_bn2\")\n",
    "        h_deconv2 = tf.nn.relu(h_deconv2)\n",
    "        \n",
    "        output_shape = [batch_size, 14, 14, g_dim*2]\n",
    "        h_deconv3 = deconv2d(h_deconv2,output_shape=output_shape,name='g_deconv3')\n",
    "        h_deconv3 = tf.contrib.layers.batch_norm(inputs=h_deconv3, center=True, scale=True, is_training=True, scope=\"g_bn3\")\n",
    "        h_deconv3 = tf.nn.relu(h_deconv3)\n",
    "        \n",
    "        output_shape = [batch_size, 28, 28, g_dim*1]\n",
    "        h_deconv4 = deconv2d(h_deconv3,output_shape=output_shape,name='g_deconv4')\n",
    "        h_deconv4 = tf.contrib.layers.batch_norm(inputs=h_deconv4, center=True, scale=True, is_training=True, scope=\"g_bn4\")\n",
    "        h_deconv4 = tf.nn.relu(h_deconv4)\n",
    "        \n",
    "        output_shape = [batch_size, 28, 28, 1]\n",
    "        h_deconv4 = deconv2d(h_deconv4,s=1,output_shape=output_shape,name='g_deconv5')\n",
    "        h_deconv4 = tf.contrib.layers.batch_norm(inputs=h_deconv4, center=True, scale=True, is_training=True, scope=\"g_bn5\")\n",
    "        \n",
    "    return tf.nn.tanh(h_deconv4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_fc(x,batch_size, z_dim,reuse=False):\n",
    "    with tf.variable_scope('generator_simple',reuse=reuse):\n",
    "        hidden_layer = tf.layers.dense(x, units=256, activation=tf.nn.relu)\n",
    "        out_layer = tf.layers.dense(hidden_layer,units=28*28)\n",
    "        out_layer = tf.nn.sigmoid(out_layer)\n",
    "        out_layer = tf.reshape(out_layer,[batch_size,28,28,1])\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, batch_size, z_dim,reuse=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):        \n",
    "        g_dim = 64 # numbers of filters of first layer of generator\n",
    "        c_dim = 1 # color dimension of output (MNIST is grayscale, so c_dim = 1 for us)\n",
    "        s = 28 # output size of the image\n",
    "        # We want to slowly upscale the image, so these values will help make that change gradual.\n",
    "        s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16)\n",
    "\n",
    "        h0 = tf.reshape(z, [batch_size, 2, 2, 25]) # tf.reshape(z, [batch_size, s16+1, s16+1, -1])\n",
    "        h0 = tf.nn.relu(h0)\n",
    "        # Dimension of h0: batch_size x 2 x 2 x 25. This is because the input dimension is 100.\n",
    "        \n",
    "        # First conv layer\n",
    "        output1_shape = [batch_size,4,4,g_dim*4]\n",
    "        W_conv1 = tf.get_variable('g_wconv1', [4, 4, output1_shape[-1], int(h0.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv1 = tf.get_variable('g_bconv1', [output1_shape[-1]], \n",
    "                                  initializer=tf.constant_initializer(0.1))\n",
    "        H_conv1 = tf.nn.conv2d_transpose(h0, W_conv1, output_shape=output1_shape, \n",
    "                                         strides=[1,2,2,1], padding='SAME')\\\n",
    "                + b_conv1\n",
    "        H_conv1 = tf.contrib.layers.batch_norm(inputs=H_conv1, center=True, scale=True, is_training=True, scope='g_bn1')\n",
    "        H_conv1 = tf.nn.relu(H_conv1)\n",
    "        #Dimensions of H_conv1 = batch_size x 3 x 3 x 256\n",
    "        \n",
    "        \n",
    "        #Second DeConv Layer\n",
    "        output2_shape = [batch_size, 7 , 7 , g_dim*2]\n",
    "        W_conv2 = tf.get_variable('g_wconv2', [4, 4, output2_shape[-1], int(H_conv1.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv2 = tf.get_variable('g_bconv2', [output2_shape[-1]], \n",
    "                                  initializer=tf.constant_initializer(.1))\n",
    "        H_conv2 = tf.nn.conv2d_transpose(H_conv1, W_conv2, output_shape=output2_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='SAME') \\\n",
    "                + b_conv2\n",
    "        H_conv2 = tf.contrib.layers.batch_norm(inputs = H_conv2, center=True, scale=True, is_training=True, scope=\"g_bn2\")\n",
    "        H_conv2 = tf.nn.relu(H_conv2)\n",
    "        #Dimensions of H_conv2 = batch_size x 6 x 6 x 128\n",
    "\n",
    "        #Third DeConv Layer\n",
    "        output3_shape = [batch_size, 14 , 14 , g_dim*1]\n",
    "        W_conv3 = tf.get_variable('g_wconv3', [4, 4, output3_shape[-1], int(H_conv2.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv3 = tf.get_variable('g_bconv3', [output3_shape[-1]], \n",
    "                                  initializer=tf.constant_initializer(.1))\n",
    "        H_conv3 = tf.nn.conv2d_transpose(H_conv2, W_conv3, output_shape=output3_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='SAME')\\\n",
    "                + b_conv3\n",
    "        H_conv3 = tf.contrib.layers.batch_norm(inputs = H_conv3, center=True, scale=True, is_training=True, scope=\"g_bn3\")\n",
    "        H_conv3 = tf.nn.relu(H_conv3)\n",
    "        #Dimensions of H_conv3 = batch_size x 12 x 12 x 64\n",
    "        \n",
    "        #Fourth DeConv Layer\n",
    "        output4_shape = [batch_size, s, s, c_dim]\n",
    "        W_conv4 = tf.get_variable('g_wconv4', [4, 4, output4_shape[-1], int(H_conv3.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv4 = tf.get_variable('g_bconv4', [output4_shape[-1]], \n",
    "                                  initializer=tf.constant_initializer(.1))\n",
    "        H_conv4 = tf.nn.conv2d_transpose(H_conv3, W_conv4, output_shape=output4_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='SAME')\\\n",
    "                + b_conv4\n",
    "        H_conv4 = tf.nn.tanh(H_conv4)\n",
    "        #Dimensions of H_conv4 = batch_size x 28 x 28 x 1\n",
    "\n",
    "    return H_conv4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "tf.reset_default_graph() # Since we changed our batch size (from 1 to 16), we need to reset our Tensorflow graph\n",
    "z_dimensions = 100\n",
    "\n",
    "x_placeholder = tf.placeholder(\"float\", shape = [batch_size,28,28,1]) #Placeholder for input images to the discriminator\n",
    "z_placeholder = tf.placeholder(tf.float32, [batch_size, z_dimensions]) #Placeholder for input noise vectors to the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call generator to get sample data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Dx = discriminator_fc(x_placeholder,batch_size,reuse=False) # Dx will hold discriminator prediction probabilities for the real MNIST images\n",
    "Gz = generator_fc(z_placeholder, batch_size, z_dimensions) # Gz holds the generated images\n",
    "Dg = discriminator_fc(Gz,batch_size, reuse=True) # Dg will hold discriminator prediction probabilities for generated images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO TASK: complete the generator loss and discriminator loss according to the objective function.\n",
    "\n",
    "Generator loss: ![generator loss](../images/generator_loss.png)\n",
    "\n",
    "Discriminator loss: ![discriminator loss](../images/discriminator_loss.png)\n",
    "\n",
    "Note that: when discriminator is updated, the generator is fixed; And when generator is updated, the discriminator is fixed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg))) # ensure forward compatibility: function needs to have logits and labels args explicitly used\n",
    "\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dx, labels = tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.zeros_like(Dg)))\n",
    "d_loss = d_loss_real + d_loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "d_vars = [var for var in tvars if 'discriminator' in var.name]\n",
    "g_vars = [var for var in tvars if 'generator' in var.name]\n",
    "print(d_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.train.AdamOptimizer()\n",
    "trainerD = tf.train.AdamOptimizer(learning_rate=0.0002).minimize(d_loss, var_list=d_vars)\n",
    "trainerG =  tf.train.AdamOptimizer(learning_rate=0.0002).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 50000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        z_batch = np.random.uniform(-1, 1, size=[batch_size, z_dimensions])\n",
    "        real_image_batch = mnist.train.next_batch(batch_size)\n",
    "        real_image_batch = np.reshape(real_image_batch[0], [batch_size,28,28,1])\n",
    "        _,d_loss_value = sess.run([trainerD, d_loss], # Update the discriminator\n",
    "                           feed_dict={z_placeholder: z_batch,\n",
    "                                      x_placeholder: real_image_batch}) \n",
    "        _,g_loss_value, g = sess.run([trainerG, g_loss, Gz],  # Update the generator\n",
    "                             feed_dict={z_placeholder:z_batch})\n",
    "\n",
    "        if i%2000==1:\n",
    "            print('g_loss: ',g_loss_value, 'd_loss: ',d_loss_value)\n",
    "            n = int(np.sqrt(batch_size))\n",
    "            canvas_orig = np.empty((28 * n, 28 * n))\n",
    "            canvas_recon = np.empty((28 * n, 28 * n))\n",
    "            for i in range(n):\n",
    "                # Display original images\n",
    "                for j in range(n):\n",
    "                    # Draw the original digits\n",
    "                    canvas_orig[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = \\\n",
    "                        real_image_batch[n*i+j].reshape([28, 28])\n",
    "                # Display reconstructed images\n",
    "                for j in range(n):\n",
    "                    # Draw the reconstructed digits\n",
    "                    canvas_recon[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = \\\n",
    "                        g[n*i+j].reshape([28, 28])\n",
    "\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(2*n,n), frameon=False)\n",
    "            axes[0].imshow(canvas_orig, origin=\"upper\", cmap=\"gray\")\n",
    "            axes[0].set_title(\"Original Images\")\n",
    "\n",
    "            axes[1].imshow(canvas_recon, origin=\"upper\", cmap=\"gray\")\n",
    "            axes[1].set_title(\"Reconstructed Images\")\n",
    "\n",
    "            axes[0].set_axis_off(); axes[1].set_axis_off()\n",
    "            plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_image = generator(z_placeholder, 1, z_dimensions, reuse=True)\n",
    "# z_batch = np.random.uniform(-1, 1, size=[1, z_dimensions])\n",
    "# temp = (sess.run(sample_image, feed_dict={z_placeholder: z_batch}))\n",
    "# my_i = temp.squeeze()\n",
    "# # plt.imshow(my_i, cmap='gray_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
