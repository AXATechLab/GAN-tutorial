{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we practice to build up an autoencoder. An autoencoder is a network system that includes a encoder and a decoder. The encoder can encode the input data to latent feature and the decoder can reconstruct the input data from the encoded latent feature.\n",
    "\n",
    "Suppose you have input data x, Enc is encoder network and Dec represents decoder network, then the output of Dec(Enc(x)) is supposed to be equal to x. \n",
    "\n",
    "Practically, we often use convolutional layers for encoder and deconvolutional layers for decoder. We will practice how to build the autoencoder with convulutional layers and deconvolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!(nvidia-smi | grep -q \"has failed\") && echo \"No GPU found!\" || nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/MNIST_data\")\n",
    "\n",
    "x_train = mnist.train.images[:55000,:]\n",
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The encoder\n",
    "\n",
    "**TASK**\n",
    "\n",
    "Build the encoder network with 2 or 3 or 4 convolutional layers. Compare the results of different number of layers. Set `stride=2` for downsampling. You can use the following helper function for code brevity\n",
    "\n",
    "The number of output_channel for current layer is mostly two times by the output_channel of previous layer, expecially when your `stride == 2`. For the first layer, we mostly use 32 or 64 or larger. It depends on the input image scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_withwb(x, k_w=3, k_h=3, input_channel=1, output_channel=8, stride=1, name='conv2d', reuse=False):\n",
    "    \"\"\"\n",
    "    k_w: kernel width\n",
    "    k_h: kernel height\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name, reuse=reuse) as scope:\n",
    "        w = tf.get_variable('w', [k_w, k_h, input_channel, output_channel],\n",
    "                            initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b = tf.get_variable('b', [output_channel], initializer=tf.constant_initializer(0))\n",
    "\n",
    "    return tf.nn.conv2d(x, w, strides=[1,stride,stride,1], padding='SAME') + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    with tf.variable_scope('encoder') as scope:\n",
    "        \n",
    "        # Encoder Hidden layer #1\n",
    "        x = tf.nn.relu(conv2d_withwb(x, input_channel=1,  output_channel=32,  stride=2, name='conv1'))\n",
    "        x = tf.nn.relu(conv2d_withwb(x, input_channel=32, output_channel=64,  stride=2, name='conv2'))\n",
    "        x = tf.nn.relu(conv2d_withwb(x, input_channel=64, output_channel=128, stride=2, name='conv3'))\n",
    "\n",
    "#         x = tf.nn.sigmoid(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The decoder\n",
    "\n",
    "**TASK**\n",
    "\n",
    "Build the encoder network with deconvolutional layer (function in the next cell `deconv2d`). \n",
    "\n",
    "Set `stride=2` for downsampling. Try with different number of layers. \n",
    "\n",
    "Be careful that the number of upsampling deconvolutional layers should be consistent with the downsampling convolutional layers.\n",
    "\n",
    "And be careful with the padding  method when the second and third dimension of input or output layer is odd (`SAME` or `VALID`. Please check the tensorflow tutorial about [tf.nn.conv2d_transpose](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose)). \n",
    "\n",
    "You can also play with the `g_dim` to see whether it makes some difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv2d(x, k_w=3, k_h=3, output_shape=[1,1,1,1], stride=2, padding='SAME', name='deconv', reuse=False):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "        w = tf.get_variable('w', [k_w, k_h, output_shape[-1], int(x.get_shape()[-1])], \n",
    "                            initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b = tf.get_variable('b', [output_shape[-1]], initializer=tf.constant_initializer(0.1))\n",
    "    \n",
    "    return b + tf.nn.conv2d_transpose(x, w, output_shape=output_shape, strides=[1,stride,stride,1], padding=padding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(x):\n",
    "    with tf.variable_scope('decoder'):\n",
    "        \n",
    "        g_dim = 64\n",
    "        \n",
    "        # Decoder Hidden layer with sigmoid activation #1\n",
    "        output1_shape = [batch_size, 7, 7, g_dim*4]\n",
    "        layer_1 = deconv2d(x,       k_w=4, k_h=4, output_shape=output1_shape, stride=2, padding='SAME', name='deconv1')\n",
    "\n",
    "        # Decoder Hidden layer with sigmoid activation #2 \n",
    "        output2_shape = [batch_size, 14 , 14 , g_dim*2]\n",
    "        layer_2 = deconv2d(layer_1, k_w=4, k_h=4, output_shape=output2_shape, stride=2, padding='SAME', name='deconv2')\n",
    "\n",
    "        # Decoder Hidden layer with sigmoid activation #3 \n",
    "        output3_shape = [batch_size, 28 , 28 , 1]\n",
    "        layer_3 = deconv2d(layer_2, k_w=4, k_h=4, output_shape=output3_shape, stride=2, padding='SAME', name='deconv3')\n",
    "\n",
    "#         output4_shape = [batch_size, 28 , 28 , 1]\n",
    "#         layer_4 = deconv2d(layer_3, k_w=4, k_h=4, output_shape=output4_shape, stride=1, padding='SAME', name='deconv4')\n",
    "\n",
    "    return tf.nn.tanh(layer_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "\n",
    "Call the encoder and the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# if you had some errors and you need to run this cell again,\n",
    "# tensorflow will complain because the operations that were \n",
    "# run successfully cannot be readded to the graph. So we reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x_placeholder = tf.placeholder(\"float\", shape = [batch_size,28,28,1])\n",
    "\n",
    "feature = encoder(x_placeholder)\n",
    "x_estimate = decoder(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "\n",
    "**TASK**\n",
    "\n",
    "Compute L2 loss between the ground truth x_placeholder and the output of autoencoder x_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_loss = tf.reduce_mean(tf.square(x_placeholder - x_estimate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the training variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "e_vars = [var for var in tvars if 'encoder' in var.name]\n",
    "d_vars = [var for var in tvars if 'decoder' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0002\n",
    "num_steps = 10000\n",
    "n = int(np.sqrt(batch_size))\n",
    "\n",
    "display_step = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(l2_loss, var_list=e_vars+d_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training\n",
    "    for i in range(1, num_steps+1):\n",
    "        # Prepare Data\n",
    "        # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "        batch_x, _ = mnist.train.next_batch(batch_size)  # mnist.test.next_batch(batch_size) for test set\n",
    "        batch_x = np.reshape(batch_x,[batch_size,28,28,1])\n",
    "        \n",
    "        # Run optimization op (backprop) and cost op (to get loss value)\n",
    "        _, loss_value, reconstructed_img = sess.run([optimizer, l2_loss, x_estimate], \n",
    "                                                 feed_dict={x_placeholder: batch_x})\n",
    "\n",
    "        # Display logs per step\n",
    "        if i % display_step == 0 or i == 1:\n",
    "            print('Step %i: Minibatch Loss: %f' % (i, loss_value))\n",
    "            \n",
    "            canvas_orig = np.empty((28 * n, 28 * n))\n",
    "            canvas_recon = np.empty((28 * n, 28 * n))\n",
    "            for i in range(n):\n",
    "\n",
    "                # Display original images\n",
    "                for j in range(n):\n",
    "                    # Draw the original digits\n",
    "                    canvas_orig[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = \\\n",
    "                        batch_x[n*i+j].reshape([28, 28])\n",
    "                # Display reconstructed images\n",
    "                for j in range(n):\n",
    "                    # Draw the reconstructed digits\n",
    "                    canvas_recon[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = \\\n",
    "                        reconstructed_img[n*i+j].reshape([28, 28])\n",
    "\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(2*n,n), frameon=False)\n",
    "            axes[0].imshow(canvas_orig, origin=\"upper\", cmap=\"gray\")\n",
    "            axes[0].set_title(\"Original Images\")\n",
    "\n",
    "            axes[1].imshow(canvas_recon, origin=\"upper\", cmap=\"gray\")\n",
    "            axes[1].set_title(\"Reconstructed Images\")\n",
    "\n",
    "            axes[0].set_axis_off(); axes[1].set_axis_off()\n",
    "            plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
